{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pymysql\n",
    "#!pip install pymssql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymssql\n",
    "import pymysql as mysql\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import requests\n",
    "#import pendulum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class stt_server:\n",
    "\n",
    "    def __init__(self, cpu_id):\n",
    "\n",
    "        # settings ++\n",
    "        self.cpu_id = cpu_id\n",
    "        self.cpu_cores = [i for i in range(0,15)]\n",
    "\n",
    "        # ms sql\n",
    "        self.sql_name = 'voice_ai'\n",
    "        self.sql_server = '10.2.4.124'\n",
    "        self.sql_login = 'ICECORP\\\\1c_sql'\n",
    "\n",
    "        # mysql\n",
    "        self.mysql_name = {\n",
    "            1: 'MICO_96',\n",
    "            2: 'asterisk',\n",
    "        }\n",
    "        self.mysql_server = '10.2.4.146'\n",
    "        self.mysql_login = 'asterisk'\n",
    "\n",
    "        #self.script_path = '/home/alex/rig1/projects/pc/call_centre_stt_server/'\n",
    "        self.script_path = ''\n",
    "        self.model_path = '/home/alex/rig1/projects/pc/vosk-api/python/example/model'\n",
    "        self.source_id = 0\n",
    "        self.sources = {\n",
    "            'call': 1,\n",
    "            'master': 2,\n",
    "        }\n",
    "        self.original_storage_path = {\n",
    "            1: '/mnt/share/audio/MSK_SRVCALL/RX_TX/',\n",
    "            2: '/mnt/share/audio/MSK_SRVCALL/REC_IN_OUT/'\n",
    "        }\n",
    "        self.temp_file_path = self.script_path+'files/'\n",
    "        # settings --\n",
    "\n",
    "        self.temp_file_name = ''\n",
    "        self.original_file_path = ''\n",
    "        self.original_file_duration\t= 0\n",
    "        self.date_y = ''\n",
    "        self.date_m = ''\n",
    "        self.date_d = ''\n",
    "        self.rec_date = ''\n",
    "\n",
    "        #store pass in file, to prevent pass publication on gitdelete_current_queue\n",
    "        with open(self.script_path+'sql.pass','r') as file:\n",
    "            self.sql_pass = file.read().replace('\\n', '')\n",
    "            file.close()\n",
    "\n",
    "        with open(self.script_path+'mysql.pass','r') as file:\n",
    "            self.mysql_pass = file.read().replace('\\n', '')\n",
    "            file.close()\n",
    "\n",
    "        self.conn = self.connect_sql()\n",
    "        self.mysql_conn = {\n",
    "            1: self.connect_mysql(1),\n",
    "            2: self.connect_mysql(2),\n",
    "        }\n",
    "        \n",
    "    def perf_log(self, step, spent_time, duration, linkedid):\n",
    "        \n",
    "        current_date = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        cursor = self.conn.cursor()\n",
    "        sql_query = \"insert into perf_log(event_date, step, time, cpu, file_name, duration, linkedid, source_id) \"\n",
    "        sql_query += \"values (\"\n",
    "        sql_query += \"'\" + current_date + \"', \"\n",
    "        sql_query += str(step) + \", \"\n",
    "        sql_query += str(spent_time) + \", \"\n",
    "        sql_query += str(self.cpu_id) + \", \"\n",
    "        sql_query += \"'\" + self.temp_file_name + \"', \"\n",
    "        sql_query += \"'\" + str(duration) + \"', \"\n",
    "        sql_query += \"'\" + str(linkedid) + \"', \"\n",
    "        sql_query += \"'\" + str(self.source_id) + \"');\"\n",
    "        print(sql_query)\n",
    "        cursor.execute(sql_query)\n",
    "        server_object.conn.commit()\n",
    "\n",
    "    def connect_sql(self):\n",
    "\n",
    "        return pymssql.connect(\n",
    "            server = self.sql_server,\n",
    "            user = self.sql_login,\n",
    "            password = self.sql_pass,\n",
    "            database = self.sql_name,\n",
    "            #autocommit=True\n",
    "        )\n",
    "\n",
    "    def connect_mysql(self, source_id):\n",
    "\n",
    "        return mysql.connect(\n",
    "            host = self.mysql_server, \n",
    "            user = self.mysql_login, \n",
    "            passwd = self.mysql_pass,\n",
    "            db = self.mysql_name[source_id],\n",
    "            #autocommit = True\n",
    "        )\n",
    "\n",
    "    def get_fs_files_list(self, queue):\n",
    "        \n",
    "        fd_list = []\n",
    "\n",
    "        if self.source_id == self.sources['call']:\n",
    "            #print('call', len(queue), self.original_file_path)\n",
    "            for root, dirs, files in os.walk(self.original_storage_path[self.source_id]):\n",
    "                #find_files += [os.path.join(root, name) for name in files if name[-4:] == '.wav'] \n",
    "                for filename in files:\n",
    "                    if filename[-4:] == '.wav' and not filename in queue:\n",
    "                        rec_source_date = re.findall(r'\\d{4}-\\d{2}-\\d{2}-\\d{2}-\\d{2}-\\d{2}', filename)\n",
    "                        if len(rec_source_date) and len(rec_source_date[0]):\n",
    "                            rec_date = rec_source_date[0][:10] + ' ' + rec_source_date[0][11:].replace('-', ':')\n",
    "\n",
    "                            if len(re.findall(r'\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}', rec_date)) == 0:\n",
    "                                rec_date = 'Null'\n",
    "                                print('0 Unable to extract date:', root, filename)\n",
    "\n",
    "                            date_string  = re.findall(r'\\d{4}-\\d{2}-\\d{2}', filename)\n",
    "                            if len(date_string):\n",
    "                                self.date_y = date_string[0][:4]\n",
    "                                self.date_m = date_string[0][5:-3]\n",
    "                                self.date_d = date_string[0][-2:]\n",
    "                                #print(date_y, date_m, date_d, filename)\n",
    "                                linkedid, dst, src = self.linkedid_by_filename(filename) # cycled query\n",
    "\n",
    "                                fd_list.append({\n",
    "                                    'filepath': root,\n",
    "                                    'filename': filename,\n",
    "                                    'rec_date': rec_date,\n",
    "                                    'src': src,\n",
    "                                    'dst': dst,\n",
    "                                    'linkedid': linkedid,\n",
    "                                })\n",
    "                        else:\n",
    "                            print('1 Unable to extract date:', root, filename)\n",
    "        \n",
    "        elif self.source_id == self.sources['master']:\n",
    "            files_list = []\n",
    "            for (dirpath, dirnames, filenames) in os.walk(self.original_storage_path[self.source_id]):\n",
    "                files_list.extend(filenames)\n",
    "                break\n",
    "\n",
    "            # get record date\n",
    "            for filename in files_list:\n",
    "                if not filename in queue:\n",
    "                    rec_date = 'Null'\n",
    "\n",
    "                    #elif self.source_id == self.sources['master']:\n",
    "                    uniqueid = re.findall(r'^\\d*.\\d*', filename)[0]\n",
    "                    cursor = self.mysql_conn[self.source_id].cursor()\n",
    "                    query = \"select calldate, src, dst from cdr where uniqueid = '\" + uniqueid + \"' limit 1;\"\n",
    "                    cursor.execute(query)  # cycled query\n",
    "                    src = ''\n",
    "                    dst = ''\n",
    "                    linkedid = uniqueid\n",
    "                    for row in cursor.fetchall():\n",
    "                        rec_date = str(row[0])\n",
    "                        src = str(row[1])\n",
    "                        dst = str(row[2])\n",
    "                    if len(re.findall(r'\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}', rec_date)) == 0:\n",
    "                        rec_date = 'Null'\n",
    "                        print('Unable to extract date from filename', filename)\n",
    "\n",
    "                    fd_list.append({\n",
    "                        'filepath': self.original_storage_path[self.source_id],\n",
    "                        'filename': filename,\n",
    "                        'rec_date': rec_date,\n",
    "                        'src': src,\n",
    "                        'dst': dst,\n",
    "                        'linkedid': linkedid,\n",
    "                    })\n",
    "\n",
    "        df = pd.DataFrame(fd_list, columns = ['filepath', 'filename', 'rec_date', 'src', 'dst', 'linkedid'])\n",
    "        df.sort_values(['rec_date', 'filename'], ascending=True, inplace=True)\n",
    "\n",
    "        return df.values\n",
    "    \n",
    "    def get_sql_complete_files(self):\n",
    "\n",
    "        cursor = self.conn.cursor()\n",
    "        sql_query = \"select distinct filename from queue where\"\n",
    "        sql_query += \" source_id='\" + str(self.source_id) + \"'\"\n",
    "        sql_query += \" order by filename;\"\n",
    "        cursor.execute(sql_query)\n",
    "        complete_files = []\n",
    "        for row in cursor.fetchall():\n",
    "            complete_files.append(row[0])\n",
    "\n",
    "        return complete_files\n",
    "    \n",
    "    def get_source_id(self, source_name):\n",
    "        for source in self.sources.items():\n",
    "            if source[0] == source_name:\n",
    "                return source[1]\n",
    "        return 0\n",
    "    \n",
    "    def set_today_ymd(self):\n",
    "        self.date_y\t= datetime.datetime.today().strftime('%Y')\n",
    "        self.date_m\t= datetime.datetime.today().strftime('%m')\n",
    "        self.date_d\t= datetime.datetime.today().strftime('%d')\n",
    "        \n",
    "    def linkedid_by_filename(self, original_file_name):\n",
    "\n",
    "        filename = original_file_name.replace('rxtx.wav', '')\n",
    "\n",
    "        \n",
    "        #print('linkedid_by_filename', self.date_y, self.date_m, self.date_d, original_file_name)\n",
    "        \n",
    "        date_from = datetime.datetime(int(self.date_y), int(self.date_m), int(self.date_d))\n",
    "        date_toto = date_from+datetime.timedelta(days=1)\n",
    "        date_from = datetime.datetime.strptime(str(date_from), '%Y-%m-%d %H:%M:%S').strftime('%Y-%m-%dT%H:%M:%S')\n",
    "        date_toto = datetime.datetime.strptime(str(date_toto), '%Y-%m-%d %H:%M:%S').strftime('%Y-%m-%dT%H:%M:%S')\n",
    "\n",
    "        mysql_conn = self.connect_mysql(self.source_id)\n",
    "\n",
    "        with mysql_conn:\n",
    "        #with self.mysql_conn[self.source_id]:\n",
    "            query = \"\"\"\n",
    "            select \n",
    "                linkedid,\n",
    "                SUBSTRING(dstchannel, 5, 4),\n",
    "                src\n",
    "                from PT1C_cdr_MICO as PT1C_cdr_MICO\n",
    "                where \n",
    "                    calldate>'\"\"\"+date_from+\"\"\"' and \n",
    "                    calldate<'\"\"\"+date_toto+\"\"\"' and \n",
    "                    PT1C_cdr_MICO.recordingfile LIKE '%\"\"\"+filename+\"\"\"%' \n",
    "                    limit 1;\"\"\"\n",
    "\n",
    "            #cursor = mysql_conn[self.source_id].cursor()\n",
    "            cursor = mysql_conn.cursor()\n",
    "            cursor.execute(query)\n",
    "            for row in cursor.fetchall():\n",
    "                linkedid, dstchannel, src = row[0], row[1], row[2]\n",
    "                #print('linkedid, dstchannel', linkedid, dstchannel)\n",
    "                return linkedid, dstchannel, src\n",
    "        return '', '', ''\n",
    "    \n",
    "    def get_fs_files_list(self, queue):\n",
    "\n",
    "        fd_list = []\n",
    "\n",
    "        if self.source_id == self.sources['call']:\n",
    "            for root, dirs, files in os.walk(self.original_storage_path[self.source_id]):\n",
    "                for filename in files:\n",
    "                    if filename[-4:] == '.wav' and not filename in queue:\n",
    "                        rec_source_date = re.findall(r'\\d{4}-\\d{2}-\\d{2}-\\d{2}-\\d{2}-\\d{2}', filename)\n",
    "                        if len(rec_source_date) and len(rec_source_date[0]):\n",
    "                            rec_date = rec_source_date[0][:10] + ' ' + rec_source_date[0][11:].replace('-', ':')\n",
    "\n",
    "                            if len(re.findall(r'\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}', rec_date)) == 0:\n",
    "                                rec_date = 'Null'\n",
    "                                print('0 Unable to extract date:', root, filename)\n",
    "\n",
    "                            date_string = re.findall(r'\\d{4}-\\d{2}-\\d{2}', filename)\n",
    "                            if len(date_string):\n",
    "                                date_y = date_string[0][:4]\n",
    "                                date_m = date_string[0][5:-3]\n",
    "                                date_d = date_string[0][-2:]\n",
    "                                linkedid, dst, src = self.linkedid_by_filename(filename, date_y, date_m, date_d)  # cycled query\n",
    "\n",
    "                                fd_list.append({\n",
    "                                    'filepath': root+'/',\n",
    "                                    'filename': filename,\n",
    "                                    'rec_date': rec_date,\n",
    "                                    'src': src,\n",
    "                                    'dst': dst,\n",
    "                                    'linkedid': linkedid,\n",
    "                                })\n",
    "                        else:\n",
    "                            print('1 Unable to extract date:', root, filename)\n",
    "                # break # ToDo: remove\n",
    "\n",
    "        elif self.source_id == self.sources['master']:\n",
    "            #print('d1 master')\n",
    "            files_list = []\n",
    "            for (dirpath, dirnames, filenames) in os.walk(self.original_storage_path[self.source_id]):\n",
    "                files_list.extend(filenames)\n",
    "                \n",
    "            #print('d2 os.walk')\n",
    "            # get record date\n",
    "            files_extracted = 0\n",
    "            files_withoud_cdr_data = 0\n",
    "            for filename in files_list:\n",
    "                if not filename in queue:\n",
    "                    rec_date = 'Null'\n",
    "                    uniqueid = re.findall(r'^\\d*.\\d*', filename)[0]\n",
    "                    cursor = self.mysql_conn[self.source_id].cursor()\n",
    "                    query = \"select calldate, src, dst from cdr where uniqueid = '\" + uniqueid + \"' limit 1;\"\n",
    "                    cursor.execute(query)  # cycled query\n",
    "                    src = ''\n",
    "                    dst = ''\n",
    "                    linkedid = uniqueid\n",
    "                    for row in cursor.fetchall():\n",
    "                        rec_date = str(row[0])\n",
    "                        src = str(row[1])\n",
    "                        dst = str(row[2])\n",
    "                    if len(re.findall(r'\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}', rec_date)) == 0:\n",
    "                        rec_date = 'Null'\n",
    "                        #print('Unable to extract date from filename', filename)\n",
    "                        files_withoud_cdr_data += 1\n",
    "                        continue\n",
    "\n",
    "                    fd_list.append({\n",
    "                        'filepath': self.original_storage_path[self.source_id],\n",
    "                        'filename': filename,\n",
    "                        'rec_date': rec_date,\n",
    "                        'src': src,\n",
    "                        'dst': dst,\n",
    "                        'linkedid': linkedid,\n",
    "                    })\n",
    "                    files_extracted += 1\n",
    "                    \n",
    "            print('master extracted:', files_extracted, 'without cdr data:', files_withoud_cdr_data)\n",
    "\n",
    "        df = pd.DataFrame(fd_list, columns=['filepath', 'filename', 'rec_date', 'src', 'dst', 'linkedid'])\n",
    "        df.sort_values(['rec_date', 'filename'], ascending=True, inplace=True)\n",
    "        \n",
    "        \n",
    "\n",
    "        return df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sorting fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server_object = stt_server(0)\n",
    "server_object.source_id = 2\n",
    "cursor = server_object.conn.cursor()\n",
    "past_in_minutes = pendulum.now().add(minutes=-6).strftime('%Y-%m-%d %H:%M:%S')\n",
    "sql_query = \"select top 3 filepath, filename, duration, source_id, \"\n",
    "sql_query += \"record_date, src, dst, linkedid from queue \"\n",
    "sql_query += \"where cpu_id='\" + str(server_object.cpu_id) + \"' \"\n",
    "sql_query += \"and ( (source_id = '2' and record_date < '\" + past_in_minutes + \"') or not source_id = '2' ) \"\n",
    "sql_query += \"order by record_date, filename;\"\n",
    "cursor.execute(sql_query)\n",
    "for row in cursor.fetchall():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mid vosk confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server_object = stt_server(0)\n",
    "server_object.source_id = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = server_object.conn.cursor()\n",
    "query = \"SELECT avg(conf) FROM transcribations where not text = '';\"\n",
    "cursor.execute(query)\n",
    "for row in cursor.fetchall():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = server_object.conn.cursor()\n",
    "query = \"SELECT count(id) FROM transcribations where not text = '';\"\n",
    "cursor.execute(query)\n",
    "for row in cursor.fetchall():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = server_object.conn.cursor()\n",
    "query = \"SELECT count(id) FROM transcribations\"\n",
    "query += \" where not text = '' \"\n",
    "query += \" and conf<0.8697060696547252;\"\n",
    "cursor.execute(query)\n",
    "for row in cursor.fetchall():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = server_object.conn.cursor()\n",
    "query = \"SELECT count(id) FROM transcribations\"\n",
    "query += \" where not text = '' \"\n",
    "query += \" and conf<0.76;\"\n",
    "cursor.execute(query)\n",
    "for row in cursor.fetchall():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = server_object.conn.cursor()\n",
    "query = \"SELECT count(id) FROM transcribations\"\n",
    "query += \" where not text = '' \"\n",
    "query += \" and conf>0.96;\"\n",
    "cursor.execute(query)\n",
    "for row in cursor.fetchall():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1c - mrm relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server_object = stt_server(0)\n",
    "server_object.source_id = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = server_object.conn.cursor()\n",
    "query = \"SELECT column_name FROM information_schema.columns WHERE table_name='transcribations';\"\n",
    "cursor.execute(query)\n",
    "for row in cursor.fetchall():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = server_object.conn.cursor()\n",
    "query = \"SELECT count(distinct linkedid) from transcribations\"\n",
    "query += \" where record_date > '2021-04-19 00:00:00' and record_date < '2021-04-20 00:00:00';\"\n",
    "cursor.execute(query)\n",
    "for row in cursor.fetchall():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = server_object.conn.cursor()\n",
    "query = \"SELECT LEN(src), count(LEN(src)) from transcribations\"\n",
    "query += \" where source_id = 2 group by LEN(src) order by count(LEN(src)) desc;\"\n",
    "cursor.execute(query)\n",
    "for row in cursor.fetchall():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = server_object.conn.cursor()\n",
    "query = \"SELECT top 20 max(record_date), src, dst, linkedid from transcribations\"\n",
    "#query += \" where source_id = 2 and LEN(dst) = 10\"\n",
    "query += \" where src = '9055316577' and dst = '89150345780'\"\n",
    "#query += \" and not substring(src,1,1) = '7'\"\n",
    "query += \" group by src, dst, linkedid;\"\n",
    "cursor.execute(query)\n",
    "for row in cursor.fetchall():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = server_object.conn.cursor()\n",
    "query = \"SELECT LEN(dst), count(LEN(dst)) from transcribations\"\n",
    "query += \" where source_id = 2 group by LEN(dst) order by count(LEN(dst)) desc;\"\n",
    "cursor.execute(query)\n",
    "for row in cursor.fetchall():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = server_object.conn.cursor()\n",
    "query = \"SELECT top 100 dst, substring(dst,1,1) from transcribations\"\n",
    "query += \" where source_id = 2 and LEN(dst) = 10  group by dst;\"\n",
    "cursor.execute(query)\n",
    "for row in cursor.fetchall():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linkedid = '1615539298.2155707'\n",
    "cursor = server_object.conn.cursor()\n",
    "query = \"SELECT start, side, text from transcribations where linkedid = '\" + linkedid + \"' order by start;\"\n",
    "cursor.execute(query)\n",
    "for row in cursor.fetchall():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naufon = '1615538028.2112236'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = server_object.conn.cursor()\n",
    "query = \"SELECT start, side, text from transcribations where linkedid = '\" + naufon + \"' order by start;\"\n",
    "cursor.execute(query)\n",
    "for row in cursor.fetchall():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server_object = stt_server(0)\n",
    "cursor = server_object.conn.cursor()\n",
    "sql_query = \"select top 3 record_date, filename, version from queue where cpu_id=1\"\n",
    "#sql_query += \" where linkedid='\" + linkedid + \"'\"\n",
    "sql_query += \" order by record_date desc;\"\n",
    "cursor.execute(sql_query)\n",
    "complete_files = []\n",
    "for row in cursor.fetchall():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### drop transcribation duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all records counter\n",
    "server_object = stt_server(0)\n",
    "server_object.source_id = 2\n",
    "cursor = server_object.conn.cursor()\n",
    "query = \"SELECT count(a.id) from transcribations as a;\"\n",
    "cursor.execute(query)\n",
    "for row in cursor.fetchall():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# duplicates counter\n",
    "server_object = stt_server(0)\n",
    "server_object.source_id = 2\n",
    "cursor = server_object.conn.cursor()\n",
    "query = \"select count(distinct a.id) from transcribations as a\"\n",
    "query += \" inner join transcribations as b\"\n",
    "query += \" on a.record_date = b.record_date\"\n",
    "query += \" and a.start = b.start\"\n",
    "query += \" and a.side = b.side\"\n",
    "query += \" and not a.id = b.id;\"\n",
    "cursor.execute(query)\n",
    "for row in cursor.fetchall():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show duplicates\n",
    "server_object = stt_server(0)\n",
    "server_object.source_id = 2\n",
    "cursor = server_object.conn.cursor()\n",
    "query = \"select a.record_date, a.start, a.source_id, a.side, a.text, b.text from transcribations as a\"\n",
    "query += \" inner join transcribations as b\"\n",
    "query += \" on a.record_date = b.record_date\"\n",
    "query += \" and a.start = b.start\"\n",
    "query += \" and a.side = b.side\"\n",
    "query += \" and not a.id = b.id;\"\n",
    "#cursor.execute(query)\n",
    "#for row in cursor.fetchall():\n",
    "#    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# duplicates remover\n",
    "server_object = stt_server(0)\n",
    "server_object.source_id = 2\n",
    "cursor = server_object.conn.cursor()\n",
    "query = \"delete from transcribations where id in\"\n",
    "query += \" (select distinct a.id as id from transcribations as a\"\n",
    "query += \" inner join transcribations as b\"\n",
    "query += \" on a.record_date = b.record_date\"\n",
    "query += \" and a.start = b.start\"\n",
    "query += \" and a.side = b.side\"\n",
    "query += \" and not a.id = b.id);\"\n",
    "cursor.execute(query)\n",
    "server_object.conn.commit()\n",
    "print('duplicates removed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### master date by linkedid fix ++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server_object = stt_server(0)\n",
    "server_object.source_id = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = server_object.conn.cursor()\n",
    "query = \"SELECT column_name FROM information_schema.columns WHERE table_name='transcribations';\"\n",
    "cursor.execute(query)\n",
    "for row in cursor.fetchall():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# last transcribed file whithout record_date\n",
    "cursor = server_object.conn.cursor()\n",
    "\n",
    "query = 'select top 1 transcribation_date, record_date, linkedid, audio_file_name, duration'\n",
    "query += ' from transcribations where record_date is Null'\n",
    "query += ' order by transcribation_date desc;'\n",
    "\n",
    "cursor.execute(query)\n",
    "for row in cursor.fetchall():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '1615447249.2130536-in.wav'\n",
    "uniqueid = re.findall(r'^\\d*.\\d*', filename)[0]\n",
    "uniqueid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_withoud_cdr_data = 0\n",
    "filename = '1615539298.2155707-out.wav'\n",
    "rec_date = 'Nulle'\n",
    "uniqueid = re.findall(r'^\\d*.\\d*', filename)[0]\n",
    "cursor = server_object.mysql_conn[server_object.source_id].cursor()\n",
    "query = \"select calldate, src, dst from cdr where linked_id = '\" + uniqueid + \"' limit 1;\"\n",
    "cursor.execute(query)  # cycled query\n",
    "src = ''\n",
    "dst = ''\n",
    "linkedid = uniqueid\n",
    "for row in cursor.fetchall():\n",
    "    rec_date = str(row[0])\n",
    "    src = str(row[1])\n",
    "    dst = str(row[2])\n",
    "if len(re.findall(r'\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}', rec_date)) == 0:\n",
    "    print('u:', uniqueid, 'r:', rec_date, 'Unable to extract date from filename:', filename)\n",
    "    rec_date = 'Null'\n",
    "    files_withoud_cdr_data += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniqueid == uniqueid_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#server_object.source_id = 2\n",
    "# cdr info by linkedid\n",
    "#uniqueid = '1615535566.2153554'\n",
    "cursor = server_object.mysql_conn[server_object.source_id].cursor()\n",
    "query = \"select calldate from cdr where uniqueid = '\"+uniqueid+\"' limit 1;\"\n",
    "cursor.execute(query)\n",
    "for row in cursor.fetchall():\n",
    "    rec_date = str(row[0])\n",
    "    print(row[0])\n",
    "\n",
    "if False:\n",
    "    for row in cursor.fetchall():\n",
    "        rec_date = str(row[0])\n",
    "        #src = str(row[1])\n",
    "        #dst = str(row[2])\n",
    "    if len(re.findall(r'\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}', rec_date)) == 0:\n",
    "        rec_date = 'Null'\n",
    "        print(rec_date, 'Unable to extract date from filename', filename)\n",
    "        #files_withoud_cdr_data += 1\n",
    "        #continue\n",
    "    else:\n",
    "        print('k', rec_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server_object.source_id == server_object.sources['master']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server_object = stt_server(0)\n",
    "server_object.source_id = 2\n",
    "complete_files = []\n",
    "#for filepath, filename, rec_date, src, dst, linkedid in server_object.get_fs_files_list(complete_files):\n",
    "    #print(filename, rec_date, linkedid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### master date by linkedid fix --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### regex filenames ++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'a2021-04-09t16:13:56b_c79101234092d_es_g1617974036.2741630-in.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniqueid = re.findall(r'\\d*\\.\\d*', filename)[0]\n",
    "uniqueid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_date = 'Null'\n",
    "version = 0\n",
    "r_d = re.findall(r'a.*b', filename)\n",
    "if len(r_d) and len(r_d[0]) == 21:\n",
    "    rec_date = r_d[0][1:][:-1].replace('t',' ')\n",
    "    print('v.1 date', rec_date)\n",
    "    src = re.findall(r'c.*d', filename)[0][1:][:-1]\n",
    "    dst = re.findall(r'e.*f', filename)[0][1:][:-1]\n",
    "    linkedid = re.findall(r'g.*h', filename)[0][1:][:-1]\n",
    "    version = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_date = re.findall(r'a.*b', filename)[0][1:][:-1]\n",
    "if len(rec_date) == 19:\n",
    "    src = re.findall(r'c.*d', filename)[0][1:][:-1]\n",
    "    dst = re.findall(r'e.*f', filename)[0][1:][:-1]\n",
    "    uniqueid = re.findall(r'g.*h', filename)[0][1:][:-1]\n",
    "rec_date, src, dst, uniqueid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### regex filenames --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server_object = stt_server(0)\n",
    "cursor = server_object.conn.cursor()\n",
    "sql_query = \"select filepath, filename, duration, source_id, \"\n",
    "sql_query += \"record_date, src, dst, linkedid from queue \"\n",
    "sql_query += \"where cpu_id='\"+str(server_object.cpu_id)+\"' \"\n",
    "sql_query += \"and source_id = '1' \" # ToDo: remove\n",
    "sql_query += \"order by ISNULL(record_date, 0) desc, record_date, linkedid, filename;\"\n",
    "processed = 0\n",
    "cursor.execute(sql_query)\n",
    "linkedid = ''\n",
    "for row in cursor.fetchall():\n",
    "\n",
    "    #queue_start = datetime.datetime.now()\n",
    "    queue_start = time.time()\n",
    "\n",
    "    original_file_path = row[0]\n",
    "    original_file_name = row[1]\n",
    "    original_file_duration = row[2]\n",
    "    server_object.source_id = row[3]\n",
    "    rec_date = row[4]\n",
    "    src = row[5]\n",
    "    dst = row[6]\n",
    "    linkedid = row[7]\n",
    "\n",
    "    files_converted = 0\n",
    "\n",
    "    if not os.path.isfile(original_file_path + original_file_name):\n",
    "        msg = 'File not found: '+ original_file_path + original_file_name\n",
    "        msg += '\\nRemoving from queue..'\n",
    "        print(msg)\n",
    "        #server_object.send_to_telegram(msg)\n",
    "        #server_object.delete_current_queue(original_file_name, linkedid)\n",
    "        continue\n",
    "    print(original_file_path + original_file_name, 'exists')\n",
    "    break\n",
    "print('k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.path.isfile('/mnt/share/audio/MSK_SRVCALL/RX_TX/RXTX_2021-03/09/in_8125609584_2021-03-09-13-54-03rxtx.wav')\n",
    "os.path.isfile('/mnt/share/audio/MSK_SRVCALL/RX_TX/RXTX_2021-03/09/in_9030102285_2021-03-09-13-51-01rxtx.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### file remove error alert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = '106129214'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('telegram_bot.token','r') as file:\n",
    "    telegram_bot_token = file.read().replace('\\n', '')\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_to_telegram(chat,message):\n",
    "    headers = {\n",
    "    \"Origin\": \"https://api.telegram.org\",\n",
    "    \"Referer\": 'https://api.telegram.org/bot' + telegram_bot_token,\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.110 Safari/537.36'}\n",
    "    #url\t= \"http://scriptlab.net/telegram/bots/relaybot/relaylocked.php?chat=\"+chat+\"&text=\"+message\n",
    "    url = 'https://api.telegram.org/bot' + telegram_bot_token\n",
    "    url += '/sendMessage?chat_id=' + str(chat)\n",
    "    url += '&text=' + str(message)\n",
    "    requests.get(url,headers = headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#myfile = \"/var/www/html/test_4.txt\"\n",
    "myfile = \"/home/alex/test_4.txt\"\n",
    "try:\n",
    "    os.remove(myfile)\n",
    "    print('succesfully removed', myfile)\n",
    "except OSError as e:  ## if failed, report it back to the user ##\n",
    "    print(\"Error: %s - %s.\" % (e.filename, e.strerror))\n",
    "    send_to_telegram(chat,'Unable to remove file:\\n' + myfile + '\\n' + str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# select\n",
    "cursor = server_object.conn.cursor()\n",
    "#sql_query = \"select * from perf_log;\"\n",
    "sql_query = \"select \"\n",
    "sql_query += \"record_date, ISNULL(record_date, 0) from queue \"\n",
    "#sql_query += \"where record_date is Null \"\n",
    "sql_query += \"order by ISNULL(record_date, 0) desc, record_date;\"\n",
    "cursor.execute(sql_query)\n",
    "rows = []\n",
    "#for row in cursor.fetchall():\n",
    "#    print(row)\n",
    "#    rows.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server_object = stt_server(0)\n",
    "server_object.source_id = 2\n",
    "cursor = server_object.conn.cursor()\n",
    "\n",
    "query = 'select '\n",
    "query += 'cpu_id, '\n",
    "query += 'sum(duration), '\n",
    "query += 'count(id) as cnt '\n",
    "\"\"\"query += 'max(record_date) as trans_date, '\n",
    "query += 'max(transcribation_date) as rec_date '\"\"\"\n",
    "query += 'from transcribations '\n",
    "query += 'where not cpu_id is null '\n",
    "query += 'group by cpu_id order by cpu_id;'\n",
    "\n",
    "\"\"\"query = 'select '\n",
    "query += 'cpu_id, '\n",
    "query += 'count(distinct filename) as filename, '\n",
    "query += 'max(record_date) as trans_date '\n",
    "#query += 'max(transcribation_date) as rec_date '\n",
    "query += 'from queue group by cpu_id order by cpu_id;'\n",
    "\"\"\"\n",
    "cursor.execute(query)\n",
    "for row in cursor.fetchall():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server_object = stt_server(0)\n",
    "server_object.source_id = 2\n",
    "cursor = server_object.conn.cursor()\n",
    "\n",
    "query = 'select '\n",
    "query += 'cpu_id, '\n",
    "query += 'sum(duration), '\n",
    "query += 'count(id) as cnt '\n",
    "query += 'from transcribations '\n",
    "query += 'where not cpu_id is null '\n",
    "query += 'group by cpu_id order by cpu_id;'\n",
    "\n",
    "cursor.execute(query)\n",
    "for row in cursor.fetchall():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server_object = stt_server(0)\n",
    "server_object.source_id = 2\n",
    "cursor = server_object.conn.cursor()\n",
    "query = 'select top 10'\n",
    "#query += 'cpu_id, '\n",
    "#query += 'count(distinct audio_file_name) as filename, '\n",
    "query += 'side, source_id, record_date as trans_date, '\n",
    "query += 'transcribation_date as rec_date '\n",
    "query += 'from transcribations order by transcribation_date desc;'\n",
    "cursor.execute(query)\n",
    "for row in cursor.fetchall():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### perf_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server_object = stt_server(0)\n",
    "server_object.source_id = 2\n",
    "\n",
    "cursor = server_object.conn.cursor()\n",
    "\n",
    "sql_query = \"select top 4 transcribation_date, count(distinct audio_file_name) from transcribations group by transcribation_date, audio_file_name order by transcribation_date desc\"\n",
    "cursor.execute(sql_query)\n",
    "for row in cursor.fetchall():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### performance monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server_object = stt_server(0)\n",
    "server_object.source_id = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ.get('WORKERS_COUNT', '0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime.datetime.now().strftime('%Y-%m-%dT%H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select\n",
    "cursor = server_object.conn.cursor()\n",
    "#sql_query = \"select * from perf_log;\"\n",
    "#sql_query = \"select top 10 filepath, filename, duration, source_id, \"\n",
    "#sql_query = \"select transcribation_date, linkedid, side, start, text \"\n",
    "sql_query = \"select cpu_id, linkedid, start, transcribation_date, text \"\n",
    "#sql_query += \"record_date, src, dst, linkedid from queue \"\n",
    "sql_query += \" from transcribations \"\n",
    "sql_query += \" where transcribation_date>'2021-09-06T14:55:00' \"\n",
    "sql_query += \" order by cpu_id, transcribation_date, linkedid, side, start;\"\n",
    "cursor.execute(sql_query)\n",
    "rows = []\n",
    "for row in cursor.fetchall():\n",
    "    print(row)\n",
    "    rows.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select\n",
    "cursor = server_object.conn.cursor()\n",
    "#sql_query = \"select * from perf_log;\"\n",
    "#sql_query = \"select top 10 filepath, filename, duration, source_id, \"\n",
    "sql_query = \"select top 10 filepath, filename, cpu_id \"\n",
    "#sql_query += \"record_date, src, dst, linkedid from queue \"\n",
    "sql_query += \" from queue \"\n",
    "#sql_query += \"where cpu_id='\"+str(server_object.cpu_id)+\"' \"\n",
    "sql_query += \"order by record_date, filename;\"\n",
    "cursor.execute(sql_query)\n",
    "rows = []\n",
    "for row in cursor.fetchall():\n",
    "    print(row)\n",
    "    rows.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server_object = stt_server(0)\n",
    "server_object.source_id = 2\n",
    "cursor = server_object.conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete from perf_log\n",
    "server_object = stt_server(0)\n",
    "sql_query = \"delete from perf_log;\"\n",
    "cursor = server_object.conn.cursor()\n",
    "cursor.execute(sql_query)\n",
    "server_object.conn.commit() # autocommit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"select event_date from perf_log where cores = 9 and event_date = '2021-03-05 14:49:12';\"\n",
    "cursor.execute(query)\n",
    "for row in cursor.fetchall():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server_object = stt_server(0)\n",
    "sql_query = \"delete from perf_log where cores = 9 and event_date = '2021-03-05 14:49:12';\"\n",
    "cursor = server_object.conn.cursor()\n",
    "#cursor.execute(sql_query)\n",
    "#server_object.conn.commit() # autocommit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select from perflog\n",
    "sql_query = \"select top 10 time, duration, linkedid from perf_log where step = 2;\"\n",
    "cursor.execute(sql_query)\n",
    "for row in cursor.fetchall():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perf_log stat: transcribing\n",
    "sql_query = \"select avg(time), avg(duration), count(linkedid) from perf_log \"\n",
    "sql_query += \"where step = 1 and source_id = 1;\"\n",
    "cursor.execute(sql_query)\n",
    "for row in cursor.fetchall():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perf_log stat: transcribing\n",
    "sql_query = \"select avg(time), avg(duration), count(linkedid) from perf_log \"\n",
    "sql_query += \"where step = 2 and source_id = 1;\"\n",
    "cursor.execute(sql_query)\n",
    "for row in cursor.fetchall():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert func\n",
    "server_object.perf_log(2, 4, 30, '9879.378429')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_start = datetime.datetime.now()\n",
    "time.sleep(2.5)\n",
    "trans_end = datetime.datetime.now()\n",
    "trans_diff_ms = (trans_end - trans_start)#.microseconds / 1000000\n",
    "'ms', trans_diff_ms.seconds# + trans_diff_ms.microseconds / 1000000b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "time.sleep(1.3)  # or do something more productive\n",
    "\n",
    "done = time.time()\n",
    "elapsed = done - start\n",
    "print(elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### last transcribed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server_object = stt_server(0)\n",
    "server_object.source_id = 2\n",
    "\n",
    "cursor = server_object.conn.cursor()\n",
    "\n",
    "#sql_query = \"select audio_file_name, linkedid, record_date, start, side, text from transcribations where source_id = '2' order by record_date, start, side;\"\n",
    "sql_query = \"select top 4 linkedid, transcribation_date, record_date, audio_file_name from transcribations \"\n",
    "sql_query += \"where linkedid = '1614577576.20753637'\"\n",
    "#sql_query += \"where source_id = '2' and \"\n",
    "#sql_query += \"transcribation_date<'2021-02-15 12:00:00' \"\n",
    "sql_query += \"order by record_date desc, start desc;\"\n",
    "cursor.execute(sql_query)\n",
    "for row in cursor.fetchall():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### date repair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check date cdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniqueid = '1612432458.1443773'\n",
    "cursor = server_object.mysql_conn[server_object.source_id].cursor()\n",
    "query = \"select calldate from cdr where uniqueid = '\"+uniqueid+\"' limit 1;\"\n",
    "cursor.execute(query)\n",
    "for row in cursor.fetchall():\n",
    "    #rec_date = str(row[0])\n",
    "    print(row[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### file list 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server_object = stt_server(0)\n",
    "server_object.source_id = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_files = server_object.get_sql_complete_files()\n",
    "len(complete_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_files = server_object.get_fs_files_list(complete_files)\n",
    "len(new_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_files[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### file list 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server_object = stt_server(0)\n",
    "server_object.source_id = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_files_2 = server_object.get_sql_complete_files()\n",
    "len(complete_files_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_files_2 = server_object.get_fs_files_list(complete_files_2)\n",
    "len(new_files_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_files_2[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_files(catalog):\n",
    "    fd_list = []\n",
    "    for root, dirs, files in os.walk(catalog):        \n",
    "        #find_files += [os.path.join(root, name) for name in files if name[-4:] == '.wav'] \n",
    "        for filename in files:\n",
    "            if filename[-4:] == '.wav':\n",
    "                #print(filename)\n",
    "                rec_source_date = re.findall(r'\\d{4}-\\d{2}-\\d{2}-\\d{2}-\\d{2}-\\d{2}', filename)\n",
    "                if len(rec_source_date) and len(rec_source_date[0]):\n",
    "                    rec_date = rec_source_date[0][:10] + ' ' + rec_source_date[0][11:].replace('-', ':')\n",
    "                    \n",
    "                    if len(re.findall(r'\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}', rec_date)) == 0:\n",
    "                        rec_date = 'Null'\n",
    "                        print('0 Unable to extract date:', root, filename)\n",
    "\n",
    "                    fd_list.append({\n",
    "                        'filepath': root,\n",
    "                        'filename': filename,\n",
    "                        'rec_date': rec_date\n",
    "                    })\n",
    "                else:\n",
    "                    print('1 Unable to extract date:', root, filename)\n",
    "    return fd_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_list = find_files(server_object.original_storage_path[server_object.source_id])\n",
    "len(fs_list), fs_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove complete files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcribed = []\n",
    "server_object = stt_server(0)\n",
    "server_object.source_id = 1\n",
    "cursor = server_object.conn.cursor()\n",
    "sql_query = \"select distinct audio_file_name as filename, date_y, date_m, date_d\"\n",
    "sql_query += \" from transcribations where source_id=1;\"\n",
    "cursor.execute(sql_query)\n",
    "for row in cursor.fetchall():\n",
    "    transcribed.append({\n",
    "                'filename': row[0],\n",
    "                'date_y': row[1],\n",
    "                'date_m': row[2],\n",
    "                'date_d': row[3],\n",
    "            })\n",
    "len(transcribed), transcribed[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_path = server_object.original_storage_path[1]\n",
    "full_path += 'RXTX_' + transcribed[0]['date_y']\n",
    "full_path += '-' + transcribed[0]['date_m'] + '/'\n",
    "full_path += transcribed[0]['date_d'] + '/'\n",
    "full_path += transcribed[0]['filename']\n",
    "os.path.isfile(full_path), full_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server_object = stt_server(0)\n",
    "server_object.set_today_ymd()\n",
    "for source_id in server_object.sources: # ['call', 'master']\n",
    "    #server_object.source_id = server_object.sources['call']\n",
    "    server_object.source_id = server_object.get_source_id(source_id)\n",
    "    complete_files\t= server_object.get_sql_complete_files()\n",
    "    incomplete_count = 0\n",
    "    complete_count = 0\n",
    "    print('server_object.source_id', server_object.source_id)\n",
    "    for filename, rec_date in server_object.get_fs_files_list():\n",
    "        print(filename, rec_date)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'hi' + chr(92)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server_object = stt_server(0)\n",
    "server_object.source_id = 2\n",
    "fd_list = server_object.get_fs_files_list()\n",
    "len(fd_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(fd_list)\n",
    "df.sort_values(['rec_date', 'filename'], ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[df.rec_date=='Null']\n",
    "for f,d in df.values:\n",
    "    print(f,d)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '1612946589.1564912-in.wav'\n",
    "uniqueid = re.findall(r'^\\d*.\\d*', filename)[0]\n",
    "uniqueid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = server_object.mysql_conn[server_object.source_id].cursor()\n",
    "query = \"select calldate from cdr where uniqueid = '\"+uniqueid+\"' limit 1;\"\n",
    "cursor.execute(query)\n",
    "for row in cursor.fetchall():\n",
    "    #rec_date = str(row[0])\n",
    "    print(row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_source_id(source_name):\n",
    "    for source in server_object.sources.items():\n",
    "        if source[0] == source_name:\n",
    "            return source[1]\n",
    "    return 0\n",
    "get_source_id('master')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server_object.rec_date = 'Null'\n",
    "filename = 'in_4957237230_2021-02-10-07-16-03rxtx.wav'\n",
    "rec_source_date = re.findall(r'\\d{4}-\\d{2}-\\d{2}-\\d{2}-\\d{2}-\\d{2}', filename)[0]                \n",
    "if len(rec_source_date):\n",
    "    server_object.rec_date = rec_source_date[:10] + ' ' + rec_source_date[11:].replace('-', ':')\n",
    "if len(re.findall(r'\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}', server_object.rec_date)) == 0:\n",
    "    print('Unable to extract date from filename', filename)\n",
    "server_object.rec_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_source_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server_object.rec_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall(r'\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}', server_object.rec_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for source_id in server_object.sources:\n",
    "    print(get_source_id(source_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server_object = stt_server(0)\n",
    "server_object.source_id = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = server_object.get_fs_files_list()\n",
    "len(files), files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete = server_object.get_sql_complete_files()\n",
    "len(complete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transcribations show columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = server_object.conn.cursor()\n",
    "query = \"SELECT column_name FROM information_schema.columns WHERE table_name='transcribations';\"\n",
    "cursor.execute(query)\n",
    "for row in cursor.fetchall():\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PT1C_cdr_MICO show columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = server_object.mysql_conn[1].cursor()\n",
    "query = \"SELECT column_name FROM information_schema.columns WHERE table_name='PT1C_cdr_MICO';\"\n",
    "cursor.execute(query)\n",
    "for row in cursor.fetchall():\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = server_object.mysql_conn[1].cursor()\n",
    "query = \"show tables;\"\n",
    "cursor.execute(query)\n",
    "for row in cursor.fetchall():\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cel columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = server_object.mysql_conn[1].cursor()\n",
    "query = \"SELECT column_name FROM information_schema.columns WHERE table_name='cel';\"\n",
    "cursor.execute(query)\n",
    "for row in cursor.fetchall():\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = server_object.mysql_conn[1].cursor()\n",
    "uniqueid = '1613647500.1738521'\n",
    "query = \"select calldate, src, dst from cdr where uniqueid = '\" + uniqueid + \"' limit 1;\"\n",
    "cursor.execute(sql_query)\n",
    "for row in cursor.fetchall():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### select from cel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = server_object.mysql_conn[1].cursor()\n",
    "\n",
    "sql_query = \"select * from cel where linkedid = '1613049028.1603159';\"\n",
    "cursor.execute(sql_query)\n",
    "for row in cursor.fetchall():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### queue show columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = server_object.conn.cursor()\n",
    "query = \"SELECT column_name FROM information_schema.columns WHERE table_name='queue';\"\n",
    "cursor.execute(query)\n",
    "for row in cursor.fetchall():\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transcribations show columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = server_object.conn.cursor()\n",
    "query = \"SELECT colu1amn_name FROM information_schema.columns WHERE table_name='transcribations';\"\n",
    "cursor.execute(query)\n",
    "for row in cursor.fetchall():\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transcribed phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "server_object = stt_server(0)\n",
    "server_object.source_id = 2\n",
    "\n",
    "cursor = server_object.conn.cursor()\n",
    "\n",
    "#sql_query = \"select audio_file_name, linkedid, record_date, start, side, text from transcribations where source_id = '2' order by record_date, start, side;\"\n",
    "sql_query = \"select top 4 conf, src, dst, audio_file_name, side, record_date from transcribations where source_id = '2' group by conf, src, dst, audio_file_name, side, record_date order by record_date desc;\"\n",
    "cursor.execute(sql_query)\n",
    "for row in cursor.fetchall():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = server_object.conn.cursor()\n",
    "\n",
    "sql_query = \"select start, side, src, dst, text from transcribations where linkedid = '1613049028.1603159'\"\n",
    "sql_query += \" order by start, side;\"\n",
    "cursor.execute(sql_query)\n",
    "for row in cursor.fetchall():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### phrases frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server_object = stt_server(0)\n",
    "server_object.source_id = 2\n",
    "\n",
    "cursor = server_object.conn.cursor()\n",
    "\n",
    "sql_query = \"select count(id), day(record_date), DATEPART(HOUR, record_date)\" \n",
    "sql_query += \" from transcribations where \"\n",
    "sql_query += \" record_date > '2021-03-01 00:00:00' and \"\n",
    "sql_query += \" text like '% %' \"\n",
    "sql_query += \" group by day(record_date), DATEPART(HOUR, record_date);\"\n",
    "#cursor.execute(sql_query)\n",
    "#for row in cursor.fetchall():\n",
    "#    print(row)\n",
    "df = read_sql()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get record date from cdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = server_object.mysql_conn[server_object.source_id].cursor()\n",
    "query = \"SELECT * FROM cdr WHERE uniqueid = '1613049028.1603159';\"\n",
    "cursor.execute(query)\n",
    "for row in cursor.fetchall():\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = server_object.mysql_conn[server_object.source_id].cursor()\n",
    "query = \"SELECT column_name FROM information_schema.columns WHERE table_name='cdr';\"\n",
    "cursor.execute(query)\n",
    "for row in cursor.fetchall():\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server_object.source_id = 2\n",
    "#server_object.original_file_name = '1612427793.1440877-in.wav'#files[0] #debug\n",
    "server_object.original_file_name = '1612427793.1440877-in.wav'#files[0] #debug\n",
    "uniqueid = re.findall(r'^\\d*.\\d*', server_object.original_file_name)[0]\n",
    "print('uniqueid', uniqueid)\n",
    "cursor = server_object.mysql_conn[server_object.source_id].cursor()\n",
    "#query = \"select src, dst from cdr where uniqueid = '\"+uniqueid+\"' limit 1;\"\n",
    "query = \"select calldate, src, dst from cdr where uniqueid = '\"+uniqueid+\"' limit 1;\"\n",
    "cursor.execute(query)\n",
    "for row in cursor.fetchall():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### insert into queue debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server_object = stt_server(0)\n",
    "sql_query = \"insert into transcribations( audio_file_name, transcribation_date, date_y, date_m, date_d, text, start, end_time, side, conf, linkedid, src, dst, record_date, source_id) values ( '1613048825.1603082-in.wav', '2021-02-11T16:51:28', '2021', '02', '11', '                ', '6.27', '15.6', '0', '0.8597108235294117', '1613048825.1603082', '', '','None' ,'2');\"\n",
    "#cursor = server_object.conn.cursor()\n",
    "#cursor.execute(sql_query)\n",
    "#server_object.conn.commit() # autocommit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'a2021-04-28t11:04:00b_c9312881912d_e9652533655_g1619597038.22506573.wav'\n",
    "r_d = re.findall(r'a.*b', filename)\n",
    "len(r_d) and len(r_d[0]) == 21\n",
    "src = re.findall(r'c.*d', filename)[0][1:][:-1]\n",
    "dst = re.findall(r'e.*f', filename)[0][1:][:-1]\n",
    "linkedid = re.findall(r'g.*h', filename)[0][1:][:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### delete from queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server_object = stt_server(0)\n",
    "#server_object.source_id = 1\n",
    "cursor = server_object.conn.cursor()\n",
    "sql_query = \"delete from queue where cpu_id > 8;\"\n",
    "#sql_query = \"delete from queue;\"\n",
    "cursor.execute(sql_query)\n",
    "server_object.conn.commit() # autocommit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "filepath = 'temp/0.wav'\n",
    "os.stat(filepath).st_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'temp/1.wav'\n",
    "os.stat(filepath).st_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'temp/x.wav'\n",
    "os.stat(filepath).st_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero = os.stat(filepath)\n",
    "zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero.st_mtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.time() - zero.st_mtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### select from queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server_object = stt_server(0)\n",
    "server_object.source_id = 2\n",
    "\n",
    "cursor = server_object.conn.cursor()\n",
    "#sql_query = \"select count(filename) from queue where source_id = '\"+str(server_object.source_id)+\"';\"\n",
    "#sql_query = \"select distinct cpu_id from queue where source_id = '\"+str(server_object.source_id)+\"';\"\n",
    "#sql_query = \"select filename, record_date, cpu_id, duration, source_id from queue \"\n",
    "#sql_query += \"where source_id='\" + str(server_object.source_id) + \"' \"\n",
    "#sql_query += \"where duration=60 \"\n",
    "#sql_query += \"order by record_date;\"\n",
    "\n",
    "print('# 1')\n",
    "#sql_query = \"select record_date, count(filename) from queue \"\n",
    "#sql_query += \"where source_id='2' and record_date is Null group by record_date;\"\n",
    "sql_query = \"select source_id, count(filename) from queue group by source_id;\"\n",
    "#sql_query = \"select distinct filename from queue where source_id = 2;\"\n",
    "#sql_query += \"limit 1;\"\n",
    "cursor.execute(sql_query)\n",
    "for row in cursor.fetchall():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "server_object = stt_server(0)\n",
    "server_object.source_id = 2\n",
    "\n",
    "cursor = server_object.conn.cursor()\n",
    "#sql_query = \"select count(filename) from queue where source_id = '\"+str(server_object.source_id)+\"';\"\n",
    "#sql_query = \"select distinct cpu_id from queue where source_id = '\"+str(server_object.source_id)+\"';\"\n",
    "#sql_query = \"select filename, record_date, cpu_id, duration, source_id from queue \"\n",
    "#sql_query += \"where source_id='\" + str(server_object.source_id) + \"' \"\n",
    "#sql_query += \"where duration=60 \"\n",
    "#sql_query += \"order by record_date;\"\n",
    "\n",
    "print('# 1')\n",
    "sql_query = \"select top 1 * from queue \"\n",
    "sql_query += \"where source_id='1';\"\n",
    "#sql_query += \"limit 1;\"\n",
    "cursor.execute(sql_query)\n",
    "for row in cursor.fetchall():\n",
    "    #print(row[0], row[1], row[2], row[3])\n",
    "    print(row)\n",
    "\n",
    "print('# 2')\n",
    "sql_query = \"select top 1 * from queue \"\n",
    "sql_query += \"where source_id='2' \"\n",
    "sql_query += \"order by record_date;\"\n",
    "#sql_query += \"limit 1;\"\n",
    "cursor.execute(sql_query)\n",
    "for row in cursor.fetchall():\n",
    "    #print(row[0], row[1], row[2], row[3])\n",
    "    print(row)\n",
    "    \n",
    "print('# count 1')\n",
    "sql_query = \"select count(filename) from queue where source_id = '1';\"\n",
    "#sql_query += \"limit 1;\"\n",
    "cursor.execute(sql_query)\n",
    "for row in cursor.fetchall():\n",
    "    #print(row[0], row[1], row[2], row[3])\n",
    "    print(row)\n",
    "    \n",
    "print('# count 2')\n",
    "sql_query = \"select count(filename) from queue where source_id = '2';\"\n",
    "#sql_query += \"limit 1;\"\n",
    "cursor.execute(sql_query)\n",
    "for row in cursor.fetchall():\n",
    "    #print(row[0], row[1], row[2], row[3])\n",
    "    print(row)\n",
    "    \n",
    "print('# cpus')\n",
    "sql_query = \"select distinct cpu_id from queue where cpu_id='30' order by cpu_id;\"\n",
    "cursor.execute(sql_query)\n",
    "for row in cursor.fetchall():\n",
    "    #print(row[0], row[1], row[2], row[3])\n",
    "    print(row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### call queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server_object = stt_server(0)\n",
    "server_object.source_id = 1\n",
    "cursor = server_object.conn.cursor()\n",
    "#sql_query = \"select top 2 * from queue where source_id='1' and duration = 0;\"\n",
    "sql_query = \"select top 200 record_date from queue where source_id='2' and duration >5 order by record_date;\"\n",
    "#sql_query = \"select count(filename) from queue where source_id='2' and duration >5;\"\n",
    "cursor.execute(sql_query)\n",
    "#for row in cursor.fetchall():    \n",
    "#    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### delete from transcribations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = server_object.conn.cursor()\n",
    "sql_query = \"delete from transcribations where source_id = '2';\"\n",
    "#cursor.execute(sql_query)\n",
    "#server_object.conn.commit() # autocommit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server_object.get_sql_complete_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### select from transcribations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server_object = stt_server(0)\n",
    "#server_object.source_id = 1\n",
    "\n",
    "cursor = server_object.conn.cursor()\n",
    "sql_query = \"select top 100 record_date, side, audio_file_name from transcribations where source_id = 2 and not record_date = '' order by record_date desc, start desc;\"\n",
    "cursor.execute(sql_query)\n",
    "for row in cursor.fetchall():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_date = datetime.datetime.now()\n",
    "DD = datetime.timedelta(days=int(365 / 2))\n",
    "crop_date = cur_date - DD\n",
    "cur_date_y = crop_date.strftime(\"%Y\")\n",
    "cur_date_m = crop_date.strftime(\"%m\")\n",
    "cur_date_d = crop_date.strftime(\"%d\")\n",
    "cur_date_y, cur_date_m, cur_date_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_date = datetime.datetime.now()\n",
    "cur_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DD = datetime.timedelta(days=int(365/2))\n",
    "crop_date = cur_date - DD\n",
    "crop_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datetime.datetime.now().year\n",
    "datetime.datetime.now().strftime(\"%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datetime.datetime.now().month\n",
    "datetime.datetime.now().strftime(\"%m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_date = datetime.datetime.strptime(\"2021-04-12T07:00:00Z\",\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "DD = datetime.timedelta(days=int(365 / 2))\n",
    "crop_date = cur_date - DD\n",
    "#datetime.datetime.strptime(str(datetime.datetime.now()),\"%m\")\n",
    "crop_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datetime.datetime.now().day\n",
    "datetime.datetime.now().strftime(\"%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from init_server import stt_server\n",
    "from deeppavlov import build_model, configs\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server_object = stt_server(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "    select top \"\"\"+str(BATCH_SIZE)+\"\"\" \n",
    "    id,\n",
    "    text,\n",
    "    sentiment\n",
    "    from transcribations \n",
    "    where sentiment is NULL and text!=''\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql(query, server_object.conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = build_model(configs.classifiers.rusentiment_bert, download=True) #download first time\n",
    "res = model(df.text)\n",
    "df['sentiment'] = model(df.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'] = ['neutral','negative','skip']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    print(index, row.id,row.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in df.values:\n",
    "    print(row.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    if row.sentiment == 'negative':\n",
    "        neg = 1\n",
    "        pos = 0\n",
    "    else:\n",
    "        neg = 0\n",
    "        pos = 1\n",
    "    query = \"update transcribations set \"\n",
    "    query += \"sentiment = '\"+row.sentiment+\"', \"\n",
    "    query += \"sentiment_neg = \"+str(neg)+\", \"\n",
    "    query += \"sentiment_pos = \"+str(pos)+\" \"\n",
    "    query += \"where id = \"+str(row.id)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment_neg']=np.zeros(len(df))\n",
    "df['sentiment_pos']=np.zeros(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments = pd.DataFrame(columns=['sentiment','sentiment_neg','sentiment_pos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments = sentiments.append(pd.DataFrame({\n",
    "    'sentiment':\n",
    "        [\n",
    "            'negative',\n",
    "            'positive',\n",
    "            'neutral',\n",
    "            'speech',\n",
    "            'skip'\n",
    "        ],\n",
    "    'sentiment_neg':\n",
    "        [\n",
    "            1,0,0,0,0\n",
    "        ],\n",
    "    'sentiment_pos':\n",
    "        [\n",
    "            0,1,1,1,1\n",
    "        ]\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.sentiment=='negative'].sentiment_neg=np.ones(len(df[df.sentiment=='negative']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.sentiment=='negative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.sentiment=='negative'].sentiment_neg=[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.sentiment=='negative'].sentiment_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_value[df.sentiment=='negative']['sentiment_neg']=np.ones(len(df[df.sentiment=='negative']))\n",
    "#df[df.sentiment!='negative']['sentiment_pos']=1\n",
    "#df.fillna(0)\n",
    "#df.set_value('C', 'x', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.sentiment=='negative']['sentiment_neg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install simplejson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pickle\n",
    "#import simplejson\n",
    "#import json\n",
    "import numpy as np\n",
    "\n",
    "telegram_users={\n",
    "    '  ':'@FrolovMaxim',\n",
    "    '  ':'@vindento',\n",
    "    '  ':'@SemyonovOleg',            \n",
    "    '  ':'@format37',\n",
    "    '  ':'@Polukhin_Vladimir',\n",
    "    '  ':'@I23vitiaz321',\n",
    "    '  ':'@SummerDevil',\n",
    "    '  ':'@nikolay3697',\n",
    "    '  ':'@MadMizyaka',\n",
    "    '  ':'@DVasilev',\n",
    "    '  ':'@Enaleven',\n",
    "    '  ':'@IlyaBoiko',\n",
    "    '  ':'@Vasilcka',\n",
    "    }\n",
    "\n",
    "#with open('users.pickle', 'wb') as fp:\n",
    "#    pickle.dump(telegram_users, fp)\n",
    "#with open(\"telegram_users.txt\", \"w\") as outfile:\n",
    "#    outfile.write(\"\\n\".join(telegram_users))\n",
    "#with open('telegram_users.json', 'wb') as file:\n",
    "    #simplejson.dump(telegram_users, file)\n",
    "#    file.write(json.dumps(telegram_users))\n",
    "#np.save('users.npy', telegram_users) \n",
    "with open('users.txt', 'w') as file:\n",
    "    file.write(str(telegram_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('users.txt', 'r') as file:\n",
    "    ty = eval(file.read())\n",
    "ty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now read the file back into a Python list object\n",
    "with open('test.txt', 'r') as f:\n",
    "    a = json.loads(f.read())\n",
    "\n",
    "#with open ('users.pickle', 'rb') as fp:\n",
    "#    tu = pickle.load(fp)\n",
    "#with open(\"outfile\", \"w\") as outfile:\n",
    "#    outfile.write(\"\\n\".join(str(item) for item in itemlist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval(str(telegram_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump( telegram_users, open( \"myfile.json\", 'w' ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install urllib3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib3\n",
    "http = urllib3.PoolManager()\n",
    "url = 'https://raw.githubusercontent.com/format37/servicedeskplus/master/sdp_monitoring/users.txt'\n",
    "response = http.request('GET', url)\n",
    "eval(response.data.decode('utf-8'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
